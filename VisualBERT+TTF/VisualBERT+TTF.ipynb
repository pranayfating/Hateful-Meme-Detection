{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "VisualBERT+TF.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kE9_rJZfF_Rf",
        "FyX6Qos3Olyg",
        "dQfmpANWZO7i",
        "OvN397kXT-S5",
        "w5BfCb_YdeX4",
        "82U--UJSAJbI",
        "CBhK1UPCcLCd",
        "btDZNM5jhUbk",
        "DLckFL32OylY",
        "FAUlE_OrUNQf",
        "HpskfGOMdoks",
        "GJlMuZ_tbvlc",
        "SyR4Q5blcnkQ",
        "ApuIb9gThV2f",
        "qDk4s7aohs6w",
        "xV-sj_wdhwCK",
        "jwcXrl0jh51I"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE9_rJZfF_Rf"
      },
      "source": [
        "## **Install MMF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtyIgblgvdoY",
        "outputId": "86a7f4e1-b3ce-40c1-fcd3-47fd606bc312"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/mmf.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'mmf' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eVZPra-wMgt",
        "outputId": "77959e54-ff14-408b-b7ce-eee545f09965"
      },
      "source": [
        "import os\n",
        "os.chdir(\"mmf\")\n",
        "!pip install --editable ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/mmf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: GitPython==3.1.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (3.1.0)\n",
            "Requirement already satisfied: matplotlib==3.3.4 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (3.3.4)\n",
            "Requirement already satisfied: omegaconf==2.0.6 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (2.0.6)\n",
            "Requirement already satisfied: demjson==2.2.4 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (2.2.4)\n",
            "Requirement already satisfied: torch<=1.8.1,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (1.8.1)\n",
            "Requirement already satisfied: pytorch-lightning==1.2.7 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (1.2.7)\n",
            "Requirement already satisfied: pycocotools==2.0.2 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (2.0.2)\n",
            "Requirement already satisfied: torchvision<=0.9.1,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.9.1)\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (1.1.0)\n",
            "Requirement already satisfied: lmdb==0.98 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.98)\n",
            "Requirement already satisfied: editdistance==0.5.3 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.5.3)\n",
            "Requirement already satisfied: torchtext==0.5.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.5.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (1.19.5)\n",
            "Requirement already satisfied: ftfy==5.8 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (5.8)\n",
            "Requirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (2.23.0)\n",
            "Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.43.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (4.49.0)\n",
            "Requirement already satisfied: fasttext==0.9.1 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.9.1)\n",
            "Requirement already satisfied: datasets==1.2.1 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (1.2.1)\n",
            "Requirement already satisfied: iopath==0.1.7 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.1.7)\n",
            "Requirement already satisfied: transformers==3.4.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (3.4.0)\n",
            "Requirement already satisfied: nltk==3.4.5 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (3.4.5)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython==3.1.0->mmf==1.0.0rc12) (4.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf==1.0.0rc12) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf==1.0.0rc12) (2.8.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf==1.0.0rc12) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf==1.0.0rc12) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf==1.0.0rc12) (0.10.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.0.6->mmf==1.0.0rc12) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.0.6->mmf==1.0.0rc12) (3.7.4.3)\n",
            "Requirement already satisfied: torchmetrics>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.7->mmf==1.0.0rc12) (0.3.1)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.7->mmf==1.0.0rc12) (0.18.2)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.7->mmf==1.0.0rc12) (2.4.1)\n",
            "Requirement already satisfied: fsspec[http]>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.7->mmf==1.0.0rc12) (2021.4.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0.2->mmf==1.0.0rc12) (56.0.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0.2->mmf==1.0.0rc12) (0.29.22)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->mmf==1.0.0rc12) (0.1.95)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->mmf==1.0.0rc12) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy==5.8->mmf==1.0.0rc12) (0.2.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf==1.0.0rc12) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf==1.0.0rc12) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf==1.0.0rc12) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf==1.0.0rc12) (2.10)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn==0.0->mmf==1.0.0rc12) (0.22.2.post1)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.1->mmf==1.0.0rc12) (2.6.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (1.1.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (0.3.3)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (3.0.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (3.10.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (2.0.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (0.70.11.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath==0.1.7->mmf==1.0.0rc12) (2.3.0)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->mmf==1.0.0rc12) (0.9.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->mmf==1.0.0rc12) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->mmf==1.0.0rc12) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->mmf==1.0.0rc12) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->mmf==1.0.0rc12) (0.0.45)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->mmf==1.0.0rc12) (3.12.4)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython==3.1.0->mmf==1.0.0rc12) (4.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (3.3.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (1.32.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (1.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (0.4.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (0.36.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (1.28.1)\n",
            "Requirement already satisfied: aiohttp; extra == \"http\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (3.7.4.post0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0->mmf==1.0.0rc12) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0->mmf==1.0.0rc12) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1->mmf==1.0.0rc12) (2018.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets==1.2.1->mmf==1.0.0rc12) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0->mmf==1.0.0rc12) (7.1.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (4.2.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (5.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (20.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (1.6.3)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (3.0.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (0.4.8)\n",
            "Installing collected packages: mmf\n",
            "  Found existing installation: mmf 1.0.0rc12\n",
            "    Can't uninstall 'mmf'. No files were found to uninstall.\n",
            "  Running setup.py develop for mmf\n",
            "Successfully installed mmf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyX6Qos3Olyg"
      },
      "source": [
        "---\n",
        "## **Download the dataset (Phase2) & convert it into *MMF* format**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "pruHlZCZht3p"
      },
      "source": [
        "#@markdown ---\n",
        "#@title <h1><b><font color='red'> --Action required!-- </b></font></h1> { run: \"auto\" }\n",
        "#@markdown First, please specify the download link and the `.zip` password which both can be taken from [DrivenData](https://www.drivendata.org/competitions/70/hateful-memes-phase-2/data/)\n",
        "\n",
        "\n",
        "YOUR_LINK_TO_DOWNLOAD_PHASE2_DATA = 'https://drivendata-competition-fb-hateful-memes-data.s3.amazonaws.com/XjiOc5ycDBRRNwbhRlgH.zip?AWSAccessKeyId=AKIARVBOBDCY4MWEDJKS&Signature=ey9vLRX9%2FMRFZRKyFOIlJiJtjmo%3D&Expires=1620143289' #@param {type:\"string\"}\n",
        "PASSWORD_OF_ZIP = 'EWryfbZyNviilcDF' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XutqDqeyJrNm",
        "outputId": "6da3a43e-2a8e-4757-cb7c-89141aeb6827"
      },
      "source": [
        "!wget -O XjiOc5ycDBRRNwbhRlgH.zip --no-check-certificate --no-proxy \"$YOUR_LINK_TO_DOWNLOAD_PHASE2_DATA\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-27 07:21:41--  https://drivendata-competition-fb-hateful-memes-data.s3.amazonaws.com/XjiOc5ycDBRRNwbhRlgH.zip?AWSAccessKeyId=AKIARVBOBDCY4MWEDJKS&Signature=ey9vLRX9%2FMRFZRKyFOIlJiJtjmo%3D&Expires=1620143289\n",
            "Resolving drivendata-competition-fb-hateful-memes-data.s3.amazonaws.com (drivendata-competition-fb-hateful-memes-data.s3.amazonaws.com)... 52.218.137.243\n",
            "Connecting to drivendata-competition-fb-hateful-memes-data.s3.amazonaws.com (drivendata-competition-fb-hateful-memes-data.s3.amazonaws.com)|52.218.137.243|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4225379472 (3.9G) [application/zip]\n",
            "Saving to: ‘XjiOc5ycDBRRNwbhRlgH.zip’\n",
            "\n",
            "XjiOc5ycDBRRNwbhRlg 100%[===================>]   3.93G  49.8MB/s    in 2m 0s   \n",
            "\n",
            "2021-04-27 07:23:41 (33.7 MB/s) - ‘XjiOc5ycDBRRNwbhRlgH.zip’ saved [4225379472/4225379472]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDzGAepgJrNp",
        "outputId": "2b7aa3fe-7bac-4cfa-de47-88738f7944c4"
      },
      "source": [
        "!mmf_convert_hm --zip_file=\"XjiOc5ycDBRRNwbhRlgH.zip\" --password=$PASSWORD_OF_ZIP --bypass_checksum 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-27 07:23:44.813049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "/content/mmf/mmf/utils/configuration.py:574: UserWarning: Device specified is 'cuda' but cuda is not present. Switching to CPU version.\n",
            "  \"Device specified is 'cuda' but cuda is not present. \"\n",
            "Data folder is /root/.cache/torch/mmf/data\n",
            "Zip path is XjiOc5ycDBRRNwbhRlgH.zip\n",
            "Copying XjiOc5ycDBRRNwbhRlgH.zip\n",
            "Unzipping XjiOc5ycDBRRNwbhRlgH.zip\n",
            "Extracting the zip can take time. Sit back and relax.\n",
            "Moving train.jsonl\n",
            "Moving dev_seen.jsonl\n",
            "Moving test_seen.jsonl\n",
            "Moving dev_unseen.jsonl\n",
            "Moving test_unseen.jsonl\n",
            "Moving img\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQfmpANWZO7i"
      },
      "source": [
        "---\n",
        "## **Finetuning from a pretrained model & Generating Submission for the Challenge**\n",
        "https://mmf.sh/docs/tutorials/checkpointing/\n",
        "\n",
        "\n",
        "> **Example**\n",
        "https://github.com/apsdehal/hm_example_mmf\n",
        "\n",
        "\n",
        "After we trained the model and evaluated on the validation set, we will generate the predictions on the test set. The prediction file should contain the following three columns:\n",
        "\n",
        "- Meme identification number, id\n",
        "- Probability that the meme is hateful, proba\n",
        "- Binary label that the meme is hateful (1) or non-hateful (0), label\n",
        "\n",
        "> With MMF you can directly generate the predictions in the required submission format with the following command: \n",
        "\n",
        "**Note**: This command will output where the generated predictions csv file is stored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8phSchWH9FN7"
      },
      "source": [
        "# Free up the disk by removing .zip, .tar files\n",
        "!rm -rf /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/features/features.tar.gz\n",
        "!rm -rf /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/XjiOc5ycDBRRNwbhRlgH.zip\n",
        "!rm -rf /content/mmf/XjiOc5ycDBRRNwbhRlgH.zip\n",
        "!rm -rf /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M1a1hRZNgHB",
        "outputId": "591237bb-4107-4be9-e1b6-5f1c51305c5e"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "!mmf_run config=\"projects/visual_bert/configs/hateful_memes/from_coco.yaml\" \\\n",
        "        model=\"visual_bert_TTF\" \\\n",
        "        dataset=hateful_memes \\\n",
        "        run_type=train_val \\\n",
        "        training.batch_size=32 \\\n",
        "        training.tensorboard=True \\\n",
        "        env.tensorboard_logdir=\"logs/fit/\" \\\n",
        "        training.checkpoint_interval=100 \\\n",
        "        training.evaluation_interval=100 \\\n",
        "        checkpoint.max_to_keep=1 \\\n",
        "        training.max_updates=3000 \\\n",
        "        training.log_interval=100 \\\n",
        "        checkpoint.resume_zoo=visual_bert.pretrained.coco.fifty_pc \\\n",
        "        training.lr_ratio=0.3 \\\n",
        "        dataset_config.hateful_memes.annotations.train[0]=\"hateful_memes/defaults/annotations/train.jsonl\" \\\n",
        "        dataset_config.hateful_memes.annotations.val[0]=\"hateful_memes/defaults/annotations/dev_unseen.jsonl\" \\\n",
        "        dataset_config.hateful_memes.annotations.test[0]=\"hateful_memes/defaults/annotations/test_unseen.jsonl\" \\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-27 07:26:17.336132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option config to projects/visual_bert/configs/hateful_memes/from_coco.yaml\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option run_type to train_val\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option training.batch_size to 32\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option training.tensorboard to True\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option env.tensorboard_logdir to logs/fit/\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option training.checkpoint_interval to 100\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option training.evaluation_interval to 100\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.max_to_keep to 1\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option training.max_updates to 3000\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option training.log_interval to 100\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_zoo to visual_bert.pretrained.coco.fifty_pc\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option training.lr_ratio to 0.3\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.train[0] to hateful_memes/defaults/annotations/train.jsonl\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.val[0] to hateful_memes/defaults/annotations/dev_unseen.jsonl\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.test[0] to hateful_memes/defaults/annotations/test_unseen.jsonl\n",
            "/content/mmf/mmf/utils/configuration.py:574: UserWarning: Device specified is 'cuda' but cuda is not present. Switching to CPU version.\n",
            "  \"Device specified is 'cuda' but cuda is not present. \"\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf: \u001b[0mLogging to: ./save/train.log\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=projects/visual_bert/configs/hateful_memes/from_coco.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=train_val', 'training.batch_size=32', 'training.tensorboard=True', 'env.tensorboard_logdir=logs/fit/', 'training.checkpoint_interval=100', 'training.evaluation_interval=100', 'checkpoint.max_to_keep=1', 'training.max_updates=3000', 'training.log_interval=100', 'checkpoint.resume_zoo=visual_bert.pretrained.coco.fifty_pc', 'training.lr_ratio=0.3', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_unseen.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_unseen.jsonl'])\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf_cli.run: \u001b[0mTorch version: 1.8.1+cu102\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf_cli.run: \u001b[0mUsing seed 20609164\n",
            "\u001b[32m2021-04-27T07:26:20 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/features/features_2020_10_01.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/features/features.tar.gz ]\n",
            "Downloading features.tar.gz: 100% 10.3G/10.3G [09:48<00:00, 17.5MB/s]\n",
            "[ Starting checksum for features.tar.gz]\n",
            "[ Checksum successful for features.tar.gz]\n",
            "Unpacking features.tar.gz\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz ]\n",
            "Downloading extras.tar.gz: 100% 211k/211k [00:00<00:00, 356kB/s] \n",
            "[ Starting checksum for extras.tar.gz]\n",
            "[ Checksum successful for extras.tar.gz]\n",
            "Unpacking extras.tar.gz\n",
            "\u001b[32m2021-04-27T07:41:25 | filelock: \u001b[0mLock 140199718461392 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "Downloading: 100% 433/433 [00:00<00:00, 311kB/s]\n",
            "\u001b[32m2021-04-27T07:41:25 | filelock: \u001b[0mLock 140199718461392 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "\u001b[32m2021-04-27T07:41:25 | filelock: \u001b[0mLock 140199578479952 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 2.46MB/s]\n",
            "\u001b[32m2021-04-27T07:41:25 | filelock: \u001b[0mLock 140199578479952 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "\u001b[32m2021-04-27T07:41:25 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-27T07:41:25 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-27T07:41:25 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-27T07:41:25 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "\u001b[32m2021-04-27T07:41:26 | filelock: \u001b[0mLock 140199577520016 acquired on /root/.cache/torch/mmf/distributed_-1/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "Downloading: 100% 440M/440M [00:06<00:00, 66.4MB/s]\n",
            "\u001b[32m2021-04-27T07:41:32 | filelock: \u001b[0mLock 140199577520016 released on /root/.cache/torch/mmf/distributed_-1/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2021-04-27T07:41:36 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2021-04-27T07:41:36 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-27T07:41:36 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/omegaconf/basecontainer.py:232: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n",
            "Use OmegaConf.to_yaml(cfg)\n",
            "\n",
            "  category=UserWarning,\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-27T07:41:36 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/omegaconf/basecontainer.py:232: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n",
            "Use OmegaConf.to_yaml(cfg)\n",
            "\n",
            "  category=UserWarning,\n",
            "\n",
            "\u001b[32m2021-04-27T07:41:36 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/models/visual_bert/visual_bert.pretrained.coco_fifty_pc.tar.gz to /root/.cache/torch/mmf/data/models/visual_bert.pretrained.coco.fifty_pc/visual_bert.pretrained.coco_fifty_pc.tar.gz ]\n",
            "Downloading visual_bert.pretrained.coco_fifty_pc.tar.gz: 100% 415M/415M [00:12<00:00, 33.1MB/s]\n",
            "[ Starting checksum for visual_bert.pretrained.coco_fifty_pc.tar.gz]\n",
            "[ Checksum successful for visual_bert.pretrained.coco_fifty_pc.tar.gz]\n",
            "Unpacking visual_bert.pretrained.coco_fifty_pc.tar.gz\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-27T07:41:57 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-27T07:41:57 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-27T07:41:57 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-27T07:41:57 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.word_embeddings.weight from model.bert.embeddings.word_embeddings.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.position_embeddings.weight from model.bert.embeddings.position_embeddings.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.token_type_embeddings.weight from model.bert.embeddings.token_type_embeddings.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.LayerNorm.weight from model.bert.embeddings.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.LayerNorm.bias from model.bert.embeddings.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.token_type_embeddings_visual.weight from model.bert.embeddings.token_type_embeddings_visual.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.position_embeddings_visual.weight from model.bert.embeddings.position_embeddings_visual.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.projection.weight from model.bert.embeddings.projection.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.projection.bias from model.bert.embeddings.projection.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.query.weight from model.bert.encoder.layer.0.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.query.bias from model.bert.encoder.layer.0.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.key.weight from model.bert.encoder.layer.0.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.key.bias from model.bert.encoder.layer.0.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.value.weight from model.bert.encoder.layer.0.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.value.bias from model.bert.encoder.layer.0.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.dense.weight from model.bert.encoder.layer.0.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.dense.bias from model.bert.encoder.layer.0.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.intermediate.dense.weight from model.bert.encoder.layer.0.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.intermediate.dense.bias from model.bert.encoder.layer.0.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.dense.weight from model.bert.encoder.layer.0.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.dense.bias from model.bert.encoder.layer.0.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.LayerNorm.weight from model.bert.encoder.layer.0.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.LayerNorm.bias from model.bert.encoder.layer.0.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.query.weight from model.bert.encoder.layer.1.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.query.bias from model.bert.encoder.layer.1.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.key.weight from model.bert.encoder.layer.1.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.key.bias from model.bert.encoder.layer.1.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.value.weight from model.bert.encoder.layer.1.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.value.bias from model.bert.encoder.layer.1.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.dense.weight from model.bert.encoder.layer.1.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.dense.bias from model.bert.encoder.layer.1.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.intermediate.dense.weight from model.bert.encoder.layer.1.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.intermediate.dense.bias from model.bert.encoder.layer.1.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.dense.weight from model.bert.encoder.layer.1.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.dense.bias from model.bert.encoder.layer.1.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.LayerNorm.weight from model.bert.encoder.layer.1.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.LayerNorm.bias from model.bert.encoder.layer.1.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.query.weight from model.bert.encoder.layer.2.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.query.bias from model.bert.encoder.layer.2.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.key.weight from model.bert.encoder.layer.2.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.key.bias from model.bert.encoder.layer.2.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.value.weight from model.bert.encoder.layer.2.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.value.bias from model.bert.encoder.layer.2.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.dense.weight from model.bert.encoder.layer.2.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.dense.bias from model.bert.encoder.layer.2.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.intermediate.dense.weight from model.bert.encoder.layer.2.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.intermediate.dense.bias from model.bert.encoder.layer.2.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.dense.weight from model.bert.encoder.layer.2.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.dense.bias from model.bert.encoder.layer.2.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.LayerNorm.weight from model.bert.encoder.layer.2.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.LayerNorm.bias from model.bert.encoder.layer.2.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.query.weight from model.bert.encoder.layer.3.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.query.bias from model.bert.encoder.layer.3.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.key.weight from model.bert.encoder.layer.3.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.key.bias from model.bert.encoder.layer.3.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.value.weight from model.bert.encoder.layer.3.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.value.bias from model.bert.encoder.layer.3.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.dense.weight from model.bert.encoder.layer.3.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.dense.bias from model.bert.encoder.layer.3.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.intermediate.dense.weight from model.bert.encoder.layer.3.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.intermediate.dense.bias from model.bert.encoder.layer.3.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.dense.weight from model.bert.encoder.layer.3.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.dense.bias from model.bert.encoder.layer.3.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.LayerNorm.weight from model.bert.encoder.layer.3.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.LayerNorm.bias from model.bert.encoder.layer.3.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.query.weight from model.bert.encoder.layer.4.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.query.bias from model.bert.encoder.layer.4.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.key.weight from model.bert.encoder.layer.4.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.key.bias from model.bert.encoder.layer.4.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.value.weight from model.bert.encoder.layer.4.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.value.bias from model.bert.encoder.layer.4.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.dense.weight from model.bert.encoder.layer.4.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.dense.bias from model.bert.encoder.layer.4.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.intermediate.dense.weight from model.bert.encoder.layer.4.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.intermediate.dense.bias from model.bert.encoder.layer.4.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.dense.weight from model.bert.encoder.layer.4.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.dense.bias from model.bert.encoder.layer.4.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.LayerNorm.weight from model.bert.encoder.layer.4.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.LayerNorm.bias from model.bert.encoder.layer.4.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.query.weight from model.bert.encoder.layer.5.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.query.bias from model.bert.encoder.layer.5.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.key.weight from model.bert.encoder.layer.5.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.key.bias from model.bert.encoder.layer.5.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.value.weight from model.bert.encoder.layer.5.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.value.bias from model.bert.encoder.layer.5.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.dense.weight from model.bert.encoder.layer.5.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.dense.bias from model.bert.encoder.layer.5.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.intermediate.dense.weight from model.bert.encoder.layer.5.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.intermediate.dense.bias from model.bert.encoder.layer.5.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.dense.weight from model.bert.encoder.layer.5.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.dense.bias from model.bert.encoder.layer.5.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.LayerNorm.weight from model.bert.encoder.layer.5.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.LayerNorm.bias from model.bert.encoder.layer.5.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.query.weight from model.bert.encoder.layer.6.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.query.bias from model.bert.encoder.layer.6.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.key.weight from model.bert.encoder.layer.6.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.key.bias from model.bert.encoder.layer.6.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.value.weight from model.bert.encoder.layer.6.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.value.bias from model.bert.encoder.layer.6.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.dense.weight from model.bert.encoder.layer.6.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.dense.bias from model.bert.encoder.layer.6.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.intermediate.dense.weight from model.bert.encoder.layer.6.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.intermediate.dense.bias from model.bert.encoder.layer.6.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.dense.weight from model.bert.encoder.layer.6.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.dense.bias from model.bert.encoder.layer.6.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.LayerNorm.weight from model.bert.encoder.layer.6.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.LayerNorm.bias from model.bert.encoder.layer.6.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.query.weight from model.bert.encoder.layer.7.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.query.bias from model.bert.encoder.layer.7.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.key.weight from model.bert.encoder.layer.7.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.key.bias from model.bert.encoder.layer.7.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.value.weight from model.bert.encoder.layer.7.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.value.bias from model.bert.encoder.layer.7.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.dense.weight from model.bert.encoder.layer.7.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.dense.bias from model.bert.encoder.layer.7.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.intermediate.dense.weight from model.bert.encoder.layer.7.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.intermediate.dense.bias from model.bert.encoder.layer.7.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.dense.weight from model.bert.encoder.layer.7.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.dense.bias from model.bert.encoder.layer.7.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.LayerNorm.weight from model.bert.encoder.layer.7.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.LayerNorm.bias from model.bert.encoder.layer.7.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.query.weight from model.bert.encoder.layer.8.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.query.bias from model.bert.encoder.layer.8.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.key.weight from model.bert.encoder.layer.8.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.key.bias from model.bert.encoder.layer.8.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.value.weight from model.bert.encoder.layer.8.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.value.bias from model.bert.encoder.layer.8.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.dense.weight from model.bert.encoder.layer.8.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.dense.bias from model.bert.encoder.layer.8.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.intermediate.dense.weight from model.bert.encoder.layer.8.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.intermediate.dense.bias from model.bert.encoder.layer.8.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.dense.weight from model.bert.encoder.layer.8.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.dense.bias from model.bert.encoder.layer.8.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.LayerNorm.weight from model.bert.encoder.layer.8.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.LayerNorm.bias from model.bert.encoder.layer.8.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.query.weight from model.bert.encoder.layer.9.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.query.bias from model.bert.encoder.layer.9.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.key.weight from model.bert.encoder.layer.9.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.key.bias from model.bert.encoder.layer.9.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.value.weight from model.bert.encoder.layer.9.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.value.bias from model.bert.encoder.layer.9.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.dense.weight from model.bert.encoder.layer.9.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.dense.bias from model.bert.encoder.layer.9.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.intermediate.dense.weight from model.bert.encoder.layer.9.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.intermediate.dense.bias from model.bert.encoder.layer.9.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.dense.weight from model.bert.encoder.layer.9.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.dense.bias from model.bert.encoder.layer.9.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.LayerNorm.weight from model.bert.encoder.layer.9.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.LayerNorm.bias from model.bert.encoder.layer.9.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.query.weight from model.bert.encoder.layer.10.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.query.bias from model.bert.encoder.layer.10.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.key.weight from model.bert.encoder.layer.10.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.key.bias from model.bert.encoder.layer.10.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.value.weight from model.bert.encoder.layer.10.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.value.bias from model.bert.encoder.layer.10.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.dense.weight from model.bert.encoder.layer.10.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.dense.bias from model.bert.encoder.layer.10.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.intermediate.dense.weight from model.bert.encoder.layer.10.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.intermediate.dense.bias from model.bert.encoder.layer.10.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.dense.weight from model.bert.encoder.layer.10.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.dense.bias from model.bert.encoder.layer.10.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.LayerNorm.weight from model.bert.encoder.layer.10.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.LayerNorm.bias from model.bert.encoder.layer.10.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.query.weight from model.bert.encoder.layer.11.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.query.bias from model.bert.encoder.layer.11.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.key.weight from model.bert.encoder.layer.11.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.key.bias from model.bert.encoder.layer.11.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.value.weight from model.bert.encoder.layer.11.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.value.bias from model.bert.encoder.layer.11.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.dense.weight from model.bert.encoder.layer.11.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.dense.bias from model.bert.encoder.layer.11.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.intermediate.dense.weight from model.bert.encoder.layer.11.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.intermediate.dense.bias from model.bert.encoder.layer.11.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.dense.weight from model.bert.encoder.layer.11.output.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.dense.bias from model.bert.encoder.layer.11.output.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.LayerNorm.weight from model.bert.encoder.layer.11.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.LayerNorm.bias from model.bert.encoder.layer.11.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.pooler.dense.weight from model.bert.pooler.dense.weight\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.pooler.dense.bias from model.bert.pooler.dense.bias\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mPretrained model loaded\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 0\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 0\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 0\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.trainers.mmf_trainer: \u001b[0mVisualBERT(\n",
            "  (model): VisualBERTForClassification(\n",
            "    (bert): VisualBERTBase(\n",
            "      (embeddings): BertVisioLinguisticEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (token_type_embeddings_visual): Embedding(2, 768)\n",
            "        (position_embeddings_visual): Embedding(512, 768)\n",
            "        (projection): Linear(in_features=2048, out_features=768, bias=True)\n",
            "      )\n",
            "      (encoder): BertEncoderJit(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Sequential(\n",
            "      (0): BertPredictionHeadTransform(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (1): Linear(in_features=768, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (losses): Losses(\n",
            "    (losses): ModuleList(\n",
            "      (0): MMFLoss(\n",
            "        (loss_criterion): CrossEntropyLoss(\n",
            "          (loss_fn): CrossEntropyLoss()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.utils.general: \u001b[0mTotal Parameters: 112044290. Trained Parameters: 112044290\n",
            "\u001b[32m2021-04-27T07:41:57 | mmf.trainers.core.training_loop: \u001b[0mStarting training...\n",
            "\u001b[32m2021-04-27T07:53:27 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T07:53:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T07:53:34 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T07:53:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T07:53:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/3000, train/hateful_memes/cross_entropy: 0.5467, train/hateful_memes/cross_entropy/avg: 0.5467, train/total_loss: 0.5467, train/total_loss/avg: 0.5467, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 3000, lr: 0., ups: 0.14, time: 11m 49s 928ms, time_since_start: 12m 10s 427ms, eta: 06h 41m 27s 876ms\n",
            "\u001b[32m2021-04-27T07:53:47 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T07:53:47 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T07:54:59 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T07:55:05 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T07:55:13 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T07:55:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T07:55:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/3000, val/hateful_memes/cross_entropy: 0.6650, val/total_loss: 0.6650, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0000, val/hateful_memes/roc_auc: 0.4941, num_updates: 100, epoch: 1, iterations: 100, max_updates: 3000, val_time: 01m 54s 728ms, best_update: 100, best_iteration: 100, best_val/hateful_memes/roc_auc: 0.494143\n",
            "\u001b[32m2021-04-27T08:07:33 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T08:07:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T08:07:38 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T08:07:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T08:07:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/3000, train/hateful_memes/cross_entropy: 0.5467, train/hateful_memes/cross_entropy/avg: 0.5531, train/total_loss: 0.5467, train/total_loss/avg: 0.5531, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 3000, lr: 0.00001, ups: 0.14, time: 12m 13s 505ms, time_since_start: 26m 18s 987ms, eta: 06h 40m 29s 635ms\n",
            "\u001b[32m2021-04-27T08:07:55 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T08:07:55 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T08:08:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T08:08:54 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T08:09:12 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T08:09:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T08:09:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/3000, val/hateful_memes/cross_entropy: 0.6853, val/total_loss: 0.6853, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0099, val/hateful_memes/roc_auc: 0.5249, num_updates: 200, epoch: 1, iterations: 200, max_updates: 3000, val_time: 01m 37s 700ms, best_update: 200, best_iteration: 200, best_val/hateful_memes/roc_auc: 0.524897\n",
            "\u001b[32m2021-04-27T08:21:33 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T08:21:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T08:21:38 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T08:21:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T08:21:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/3000, train/hateful_memes/cross_entropy: 0.5596, train/hateful_memes/cross_entropy/avg: 0.5723, train/total_loss: 0.5596, train/total_loss/avg: 0.5723, experiment: run, epoch: 2, num_updates: 300, iterations: 300, max_updates: 3000, lr: 0.00001, ups: 0.13, time: 12m 22s 180ms, time_since_start: 40m 18s 871ms, eta: 06h 30m 45s 498ms\n",
            "\u001b[32m2021-04-27T08:21:55 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T08:21:55 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T08:22:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T08:22:39 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T08:22:53 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T08:23:16 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T08:23:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/3000, val/hateful_memes/cross_entropy: 0.6695, val/total_loss: 0.6695, val/hateful_memes/accuracy: 0.6204, val/hateful_memes/binary_f1: 0.3731, val/hateful_memes/roc_auc: 0.5904, num_updates: 300, epoch: 2, iterations: 300, max_updates: 3000, val_time: 01m 20s 577ms, best_update: 300, best_iteration: 300, best_val/hateful_memes/roc_auc: 0.590397\n",
            "\u001b[32m2021-04-27T08:35:22 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T08:35:22 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T08:35:28 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T08:35:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T08:35:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/3000, train/hateful_memes/cross_entropy: 0.5467, train/hateful_memes/cross_entropy/avg: 0.5554, train/total_loss: 0.5467, train/total_loss/avg: 0.5554, experiment: run, epoch: 2, num_updates: 400, iterations: 400, max_updates: 3000, lr: 0.00001, ups: 0.13, time: 12m 29s 086ms, time_since_start: 54m 08s 559ms, eta: 06h 19m 47s 211ms\n",
            "\u001b[32m2021-04-27T08:35:45 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T08:35:45 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T08:36:22 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T08:36:28 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T08:36:42 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T08:37:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T08:37:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/3000, val/hateful_memes/cross_entropy: 0.6981, val/total_loss: 0.6981, val/hateful_memes/accuracy: 0.6370, val/hateful_memes/binary_f1: 0.3423, val/hateful_memes/roc_auc: 0.6267, num_updates: 400, epoch: 2, iterations: 400, max_updates: 3000, val_time: 01m 20s 127ms, best_update: 400, best_iteration: 400, best_val/hateful_memes/roc_auc: 0.626662\n",
            "\u001b[32m2021-04-27T08:49:04 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T08:49:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T08:49:10 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T08:49:28 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T08:49:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/3000, train/hateful_memes/cross_entropy: 0.5467, train/hateful_memes/cross_entropy/avg: 0.5439, train/total_loss: 0.5467, train/total_loss/avg: 0.5439, experiment: run, epoch: 2, num_updates: 500, iterations: 500, max_updates: 3000, lr: 0.00001, ups: 0.13, time: 12m 23s 060ms, time_since_start: 01h 07m 51s 750ms, eta: 06h 02m 14s 508ms\n",
            "\u001b[32m2021-04-27T08:49:28 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T08:49:28 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T08:50:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T08:50:11 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T08:50:29 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T08:50:50 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T08:50:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/3000, val/hateful_memes/cross_entropy: 0.6575, val/total_loss: 0.6575, val/hateful_memes/accuracy: 0.6611, val/hateful_memes/binary_f1: 0.4633, val/hateful_memes/roc_auc: 0.6732, num_updates: 500, epoch: 2, iterations: 500, max_updates: 3000, val_time: 01m 21s 303ms, best_update: 500, best_iteration: 500, best_val/hateful_memes/roc_auc: 0.673206\n",
            "\u001b[32m2021-04-27T09:03:18 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T09:03:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T09:03:23 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T09:03:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T09:03:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/3000, train/hateful_memes/cross_entropy: 0.5048, train/hateful_memes/cross_entropy/avg: 0.5142, train/total_loss: 0.5048, train/total_loss/avg: 0.5142, experiment: run, epoch: 3, num_updates: 600, iterations: 600, max_updates: 3000, lr: 0.00002, ups: 0.13, time: 12m 52s 231ms, time_since_start: 01h 22m 05s 287ms, eta: 06h 01m 24s 259ms\n",
            "\u001b[32m2021-04-27T09:03:42 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T09:03:42 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T09:04:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T09:04:29 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T09:04:43 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T09:05:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T09:05:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/3000, val/hateful_memes/cross_entropy: 0.7145, val/total_loss: 0.7145, val/hateful_memes/accuracy: 0.6611, val/hateful_memes/binary_f1: 0.4116, val/hateful_memes/roc_auc: 0.6844, num_updates: 600, epoch: 3, iterations: 600, max_updates: 3000, val_time: 01m 25s 164ms, best_update: 600, best_iteration: 600, best_val/hateful_memes/roc_auc: 0.684397\n",
            "\u001b[32m2021-04-27T09:17:25 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T09:17:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T09:17:30 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T09:17:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T09:17:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/3000, train/hateful_memes/cross_entropy: 0.5048, train/hateful_memes/cross_entropy/avg: 0.4960, train/total_loss: 0.5048, train/total_loss/avg: 0.4960, experiment: run, epoch: 3, num_updates: 700, iterations: 700, max_updates: 3000, lr: 0.00002, ups: 0.13, time: 12m 40s 302ms, time_since_start: 01h 36m 10s 757ms, eta: 05h 40m 59s 747ms\n",
            "\u001b[32m2021-04-27T09:17:47 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T09:17:47 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T09:18:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T09:18:30 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T09:18:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T09:18:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/3000, val/hateful_memes/cross_entropy: 0.7243, val/total_loss: 0.7243, val/hateful_memes/accuracy: 0.6630, val/hateful_memes/binary_f1: 0.4615, val/hateful_memes/roc_auc: 0.6767, num_updates: 700, epoch: 3, iterations: 700, max_updates: 3000, val_time: 59s 583ms, best_update: 600, best_iteration: 600, best_val/hateful_memes/roc_auc: 0.684397\n",
            "\u001b[32m2021-04-27T09:31:15 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T09:31:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T09:31:20 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T09:31:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T09:31:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/3000, train/hateful_memes/cross_entropy: 0.4978, train/hateful_memes/cross_entropy/avg: 0.4604, train/total_loss: 0.4978, train/total_loss/avg: 0.4604, experiment: run, epoch: 4, num_updates: 800, iterations: 800, max_updates: 3000, lr: 0.00002, ups: 0.13, time: 12m 50s 608ms, time_since_start: 01h 50m 953ms, eta: 05h 30m 35s 470ms\n",
            "\u001b[32m2021-04-27T09:31:37 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T09:31:37 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T09:32:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T09:32:32 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T09:32:46 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T09:33:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T09:33:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/3000, val/hateful_memes/cross_entropy: 0.7686, val/total_loss: 0.7686, val/hateful_memes/accuracy: 0.6593, val/hateful_memes/binary_f1: 0.3285, val/hateful_memes/roc_auc: 0.6856, num_updates: 800, epoch: 4, iterations: 800, max_updates: 3000, val_time: 01m 32s 454ms, best_update: 800, best_iteration: 800, best_val/hateful_memes/roc_auc: 0.685588\n",
            "\u001b[32m2021-04-27T09:45:52 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T09:45:52 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T09:45:57 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T09:46:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T09:46:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/3000, train/hateful_memes/cross_entropy: 0.4978, train/hateful_memes/cross_entropy/avg: 0.4334, train/total_loss: 0.4978, train/total_loss/avg: 0.4334, experiment: run, epoch: 4, num_updates: 900, iterations: 900, max_updates: 3000, lr: 0.00002, ups: 0.13, time: 13m 02s 684ms, time_since_start: 02h 04m 36s 094ms, eta: 05h 20m 30s 557ms\n",
            "\u001b[32m2021-04-27T09:46:13 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T09:46:13 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T09:46:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T09:47:01 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T09:47:18 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T09:47:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T09:47:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/3000, val/hateful_memes/cross_entropy: 0.8146, val/total_loss: 0.8146, val/hateful_memes/accuracy: 0.6852, val/hateful_memes/binary_f1: 0.4371, val/hateful_memes/roc_auc: 0.7042, num_updates: 900, epoch: 4, iterations: 900, max_updates: 3000, val_time: 01m 26s 848ms, best_update: 900, best_iteration: 900, best_val/hateful_memes/roc_auc: 0.704191\n",
            "\u001b[32m2021-04-27T10:00:08 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T10:00:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T10:00:13 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T10:00:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T10:00:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/3000, train/hateful_memes/cross_entropy: 0.3864, train/hateful_memes/cross_entropy/avg: 0.4229, train/total_loss: 0.3864, train/total_loss/avg: 0.4229, experiment: run, epoch: 4, num_updates: 1000, iterations: 1000, max_updates: 3000, lr: 0.00003, ups: 0.13, time: 12m 50s 999ms, time_since_start: 02h 18m 53s 945ms, eta: 05h 41s 385ms\n",
            "\u001b[32m2021-04-27T10:00:32 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T10:00:32 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T10:01:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T10:01:15 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T10:01:35 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T10:01:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T10:01:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/3000, val/hateful_memes/cross_entropy: 0.6492, val/total_loss: 0.6492, val/hateful_memes/accuracy: 0.6815, val/hateful_memes/binary_f1: 0.5196, val/hateful_memes/roc_auc: 0.7196, num_updates: 1000, epoch: 4, iterations: 1000, max_updates: 3000, val_time: 01m 23s 321ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.719618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywzqDzv2qImf",
        "outputId": "e8e63046-f06c-4470-dc9a-823932b8dc09"
      },
      "source": [
        "!mmf_run config=\"projects/visual_bert/configs/hateful_memes/defaults.yaml\" \\\n",
        "    model=\"visual_bert_TTF\" \\\n",
        "    dataset=hateful_memes \\\n",
        "    run_type=val \\\n",
        "    checkpoint.resume_file=\"/content/save/best.ckpt\" \\\n",
        "    dataset_config.hateful_memes.annotations.test[0]=\"hateful_memes/defaults/annotations/test_unseen.jsonl\" \\\n",
        "    dataset_config.hateful_memes.annotations.val[0]=\"hateful_memes/defaults/annotations/dev_unseen.jsonl\" \\\n",
        "    dataset_config.hateful_memes.features.train[0]=\"/content/features\" \\\n",
        "    dataset_config.hateful_memes.features.val[0]=\"/content/features\" \\\n",
        "    dataset_config.hateful_memes.features.test[0]=\"/content/features\" \\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m2021-04-27T12:11:57 | mmf.utils.general:\u001b[0m  Total Parameters: 123503490. Trained Parameters: 112144794\u001b[0m\n",
            "\u001b[32m2021-04-27T12:11:57 | mmf.trainers.core.training_loop:\u001b[0m  Starting training...\u001b[0m\n",
            "\u001b[32m2021-04-27T12:23:27 | mmf.trainers.callbacks.checkpoint:\u001b[0m  Checkpoint time. Saving a checkpoint.\u001b[0m\n",
            "\u001b[32m2021-04-27T12:23:27 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T12:23:28 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T12:23:47 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T12:23:51 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 100/1000, train/hateful_memes/cross_entropy: 0.5477, train/hateful_memes/cross_entropy/avg: 0.5477, train/total_loss: 0.5477, train/total_loss/avg: 0.5477, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 1000, lr: 0., ups: 0.14, time: 11m 49s 928ms, time_since_start: 12m 10s 427ms, eta: 03h 48m 27s 846ms\u001b[0m\n",
            "\u001b[32m2021-04-27T12:23:55 | mmf.trainers.core.training_loop:\u001b[0m  Evaluation time. Running on full training set...\u001b[0m\n",
            "\u001b[32m2021-04-27T12:23:47 | mmf.common.test_reporter:\u001b[0m  Predicting for hateful_memes\u001b[0m\n",
            "\u001b[32m2021-04-27T12:54:59 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T12:55:05 | mmf.utils.checkpoint:\u001b[0m  Saving best checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T12:55:13 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T12:55:42 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T12:55:42 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 100/1000, test/hateful_memes/cross_entropy: 0.6650, test/total_loss: 0.6650, test/hateful_memes/accuracy: 0.6196, test/hateful_memes/binary_f1: 0.0000, test/hateful_memes/roc_auc: 0.4941, num_updates: 100, epoch: 1, iterations: 100, max_updates: 1000, val_time: 01m 54s 728ms, best_update: 100, best_iteration: 100, best_test/hateful_memes/roc_auc: 0.494143\u001b[0m\n",
            "\u001b[32m2021-04-27T13:10:33 | mmf.trainers.callbacks.checkpoint:\u001b[0m  Checkpoint time. Saving a checkpoint.\u001b[0m\n",
            "\u001b[32m2021-04-27T13:10:39 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T13:10:38 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T13:10:55 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T13:10:55 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 200/1000, train/hateful_memes/cross_entropy: 0.5577, train/hateful_memes/cross_entropy/avg: 0.5531, train/total_loss: 0.5477, train/total_loss/avg: 0.5531, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 1000, lr: 0.00001, ups: 0.14, time: 12m 13s 505ms, time_since_start: 26m 18s 987ms, eta: 03h 48m 29s 685ms\u001b[0m\n",
            "\u001b[32m2021-04-27T13:10:55 | mmf.trainers.core.training_loop:\u001b[0m  Evaluation time. Running on full training set...\u001b[0m\n",
            "\u001b[32m2021-04-27T13:10:55 | mmf.common.test_reporter:\u001b[0m  Predicting for hateful_memes\u001b[0m\n",
            "\u001b[32m2021-04-27T13:12:47 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T13:12:54 | mmf.utils.checkpoint:\u001b[0m  Saving best checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T13:13:12 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T13:13:33 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T13:13:33 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 200/1000, test/hateful_memes/cross_entropy: 0.6853, test/total_loss: 0.6853, test/hateful_memes/accuracy: 0.6196, test/hateful_memes/binary_f1: 0.0099, test/hateful_memes/roc_auc: 0.5249, num_updates: 200, epoch: 1, iterations: 200, max_updates: 1000, val_time: 01m 37s 700ms, best_update: 200, best_iteration: 200, best_test/hateful_memes/roc_auc: 0.524897\u001b[0m\n",
            "\u001b[32m2021-04-27T13:13:43 | mmf.trainers.callbacks.checkpoint:\u001b[0m  Checkpoint time. Saving a checkpoint.\u001b[0m\n",
            "\u001b[32m2021-04-27T13:21:54 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T13:21:38 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T13:21:55 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T13:21:55 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 300/1000, train/hateful_memes/cross_entropy: 0.5596, train/hateful_memes/cross_entropy/avg: 0.5723, train/total_loss: 0.5596, train/total_loss/avg: 0.5723, experiment: run, epoch: 2, num_updates: 300, iterations: 300, max_updates: 1000, lr: 0.00001, ups: 0.13, time: 12m 22s 180ms, time_since_start: 40m 18s 871ms, eta: 03h 30m 45s 408ms\u001b[0m\n",
            "\u001b[32m2021-04-27T13:21:55 | mmf.trainers.core.training_loop:\u001b[0m  Evaluation time. Running on full training set...\u001b[0m\n",
            "\u001b[32m2021-04-27T13:21:55 | mmf.common.test_reporter:\u001b[0m  Predicting for hateful_memes\u001b[0m\n",
            "\u001b[32m2021-04-27T13:22:33 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T13:22:39 | mmf.utils.checkpoint:\u001b[0m  Saving best checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T13:22:53 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T13:23:16 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T13:23:16 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 300/1000, test/hateful_memes/cross_entropy: 0.6695, test/total_loss: 0.6695, test/hateful_memes/accuracy: 0.6104, test/hateful_memes/binary_f1: 0.3731, test/hateful_memes/roc_auc: 0.5904, num_updates: 300, epoch: 2, iterations: 300, max_updates: 1000, val_time: 01m 20s 577ms, best_update: 300, best_iteration: 300, best_test/hateful_memes/roc_auc: 0.590397\u001b[0m\n",
            "\u001b[32m2021-04-27T13:35:22 | mmf.trainers.callbacks.checkpoint:\u001b[0m  Checkpoint time. Saving a checkpoint.\u001b[0m\n",
            "\u001b[32m2021-04-27T13:35:22 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T13:35:28 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T13:35:45 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T13:35:45 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 400/1000, train/hateful_memes/cross_entropy: 0.5577, train/hateful_memes/cross_entropy/avg: 0.5554, train/total_loss: 0.5477, train/total_loss/avg: 0.5554, experiment: run, epoch: 2, num_updates: 400, iterations: 400, max_updates: 1000, lr: 0.00001, ups: 0.13, time: 12m 29s 086ms, time_since_start: 54m 08s 559ms, eta: 03h 19m 47s 211ms\u001b[0m\n",
            "\u001b[32m2021-04-27T13:35:45 | mmf.trainers.core.training_loop:\u001b[0m  Evaluation time. Running on full training set...\u001b[0m\n",
            "\u001b[32m2021-04-27T13:35:45 | mmf.common.test_reporter:\u001b[0m  Predicting for hateful_memes\u001b[0m\n",
            "\u001b[32m2021-04-27T13:36:22 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T13:36:28 | mmf.utils.checkpoint:\u001b[0m  Saving best checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T13:36:42 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T13:37:05 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T13:37:05 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 400/1000, test/hateful_memes/cross_entropy: 0.6981, test/total_loss: 0.6981, test/hateful_memes/accuracy: 0.6270, test/hateful_memes/binary_f1: 0.3423, test/hateful_memes/roc_auc: 0.6267, num_updates: 400, epoch: 2, iterations: 400, max_updates: 1000, val_time: 01m 20s 127ms, best_update: 400, best_iteration: 400, best_test/hateful_memes/roc_auc: 0.626662\u001b[0m\n",
            "\u001b[32m2021-04-27T13:49:04 | mmf.trainers.callbacks.checkpoint:\u001b[0m  Checkpoint time. Saving a checkpoint.\u001b[0m\n",
            "\u001b[32m2021-04-27T13:49:04 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T13:49:10 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T13:49:28 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T13:49:28 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 500/1000, train/hateful_memes/cross_entropy: 0.5577, train/hateful_memes/cross_entropy/avg: 0.5439, train/total_loss: 0.5477, train/total_loss/avg: 0.5439, experiment: run, epoch: 2, num_updates: 500, iterations: 500, max_updates: 1000, lr: 0.00001, ups: 0.13, time: 12m 23s 060ms, time_since_start: 01h 07m 51s 750ms, eta: 03h 02m 14s 508ms\u001b[0m\n",
            "\u001b[32m2021-04-27T13:49:28 | mmf.trainers.core.training_loop:\u001b[0m  Evaluation time. Running on full training set...\u001b[0m\n",
            "\u001b[32m2021-04-27T13:49:28 | mmf.common.test_reporter:\u001b[0m  Predicting for hateful_memes\u001b[0m\n",
            "\u001b[32m2021-04-27T13:50:05 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T13:50:11 | mmf.utils.checkpoint:\u001b[0m  Saving best checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T13:50:29 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T13:50:50 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T13:50:50 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 500/1000, test/hateful_memes/cross_entropy: 0.6575, test/total_loss: 0.6575, test/hateful_memes/accuracy: 0.6521, test/hateful_memes/binary_f1: 0.4733, test/hateful_memes/roc_auc: 0.6732, num_updates: 500, epoch: 2, iterations: 500, max_updates: 1000, val_time: 01m 21s 303ms, best_update: 500, best_iteration: 500, best_test/hateful_memes/roc_auc: 0.673206\u001b[0m\n",
            "\u001b[32m2021-04-27T14:03:18 | mmf.trainers.callbacks.checkpoint:\u001b[0m  Checkpoint time. Saving a checkpoint.\u001b[0m\n",
            "\u001b[32m2021-04-27T14:03:18 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T14:03:23 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T14:03:42 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T14:03:42 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 600/1000, train/hateful_memes/cross_entropy: 0.5048, train/hateful_memes/cross_entropy/avg: 0.5142, train/total_loss: 0.5048, train/total_loss/avg: 0.5142, experiment: run, epoch: 3, num_updates: 600, iterations: 600, max_updates: 1000, lr: 0.00002, ups: 0.13, time: 12m 52s 231ms, time_since_start: 01h 22m 05s 287ms, eta: 03h 01m 24s 259ms\u001b[0m\n",
            "\u001b[32m2021-04-27T14:03:42 | mmf.trainers.core.training_loop:\u001b[0m  Evaluation time. Running on full training set...\u001b[0m\n",
            "\u001b[32m2021-04-27T14:03:42 | mmf.common.test_reporter:\u001b[0m  Predicting for hateful_memes\u001b[0m\n",
            "\u001b[32m2021-04-27T14:04:23 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T14:04:29 | mmf.utils.checkpoint:\u001b[0m  Saving best checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T14:04:43 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T14:05:07 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T14:05:07 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 600/1000, test/hateful_memes/cross_entropy: 0.7145, test/total_loss: 0.7145, test/hateful_memes/accuracy: 0.6611, test/hateful_memes/binary_f1: 0.4116, test/hateful_memes/roc_auc: 0.6844, num_updates: 600, epoch: 3, iterations: 600, max_updates: 1000, val_time: 01m 25s 164ms, best_update: 600, best_iteration: 600, best_test/hateful_memes/roc_auc: 0.684397\u001b[0m\n",
            "\u001b[32m2021-04-27T14:17:25 | mmf.trainers.callbacks.checkpoint:\u001b[0m  Checkpoint time. Saving a checkpoint.\u001b[0m\n",
            "\u001b[32m2021-04-27T14:17:25 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T14:17:30 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T14:17:47 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T14:17:47 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 700/1000, train/hateful_memes/cross_entropy: 0.5048, train/hateful_memes/cross_entropy/avg: 0.4960, train/total_loss: 0.5048, train/total_loss/avg: 0.4960, experiment: run, epoch: 3, num_updates: 700, iterations: 700, max_updates: 1000, lr: 0.00002, ups: 0.13, time: 12m 40s 302ms, time_since_start: 01h 36m 10s 757ms, eta: 02h 40m 59s 747ms\u001b[0m\n",
            "\u001b[32m2021-04-27T14:17:47 | mmf.trainers.core.training_loop:\u001b[0m  Evaluation time. Running on full training set...\u001b[0m\n",
            "\u001b[32m2021-04-27T14:17:47 | mmf.common.test_reporter:\u001b[0m  Predicting for hateful_memes\u001b[0m\n",
            "\u001b[32m2021-04-27T14:18:24 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T14:18:30 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T14:18:47 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T14:18:47 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 700/1000, test/hateful_memes/cross_entropy: 0.7243, test/total_loss: 0.7243, test/hateful_memes/accuracy: 0.6630, test/hateful_memes/binary_f1: 0.4715, test/hateful_memes/roc_auc: 0.6797, num_updates: 700, epoch: 3, iterations: 700, max_updates: 1000, val_time: 59s 583ms, best_update: 600, best_iteration: 600, best_test/hateful_memes/roc_auc: 0.684397\u001b[0m\n",
            "\u001b[32m2021-04-27T14:31:15 | mmf.trainers.callbacks.checkpoint:\u001b[0m  Checkpoint time. Saving a checkpoint.\u001b[0m\n",
            "\u001b[32m2021-04-27T14:31:15 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T14:31:20 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T14:31:37 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T14:31:37 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 800/1000, train/hateful_memes/cross_entropy: 0.4978, train/hateful_memes/cross_entropy/avg: 0.4704, train/total_loss: 0.4978, train/total_loss/avg: 0.4704, experiment: run, epoch: 4, num_updates: 800, iterations: 800, max_updates: 1000, lr: 0.00002, ups: 0.13, time: 12m 50s 608ms, time_since_start: 01h 50m 953ms, eta: 02h 31m 33s 470ms\u001b[0m\n",
            "\u001b[32m2021-04-27T14:31:37 | mmf.trainers.core.training_loop:\u001b[0m  Evaluation time. Running on full training set...\u001b[0m\n",
            "\u001b[32m2021-04-27T14:31:37 | mmf.common.test_reporter:\u001b[0m  Predicting for hateful_memes\u001b[0m\n",
            "\u001b[32m2021-04-27T14:32:26 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T14:32:32 | mmf.utils.checkpoint:\u001b[0m  Saving best checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T14:32:47 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T14:33:10 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T14:33:10 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 800/1000, test/hateful_memes/cross_entropy: 0.7686, test/total_loss: 0.7686, test/hateful_memes/accuracy: 0.6593, test/hateful_memes/binary_f1: 0.3785, test/hateful_memes/roc_auc: 0.6956, num_updates: 800, epoch: 4, iterations: 800, max_updates: 1000, val_time: 01m 32s 454ms, best_update: 800, best_iteration: 800, best_test/hateful_memes/roc_auc: 0.685453\u001b[0m\n",
            "\u001b[32m2021-04-27T14:45:52 | mmf.trainers.callbacks.checkpoint:\u001b[0m  Checkpoint time. Saving a checkpoint.\u001b[0m\n",
            "\u001b[32m2021-04-27T14:45:52 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T14:45:57 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T14:47:13 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T14:47:13 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 900/1000, train/hateful_memes/cross_entropy: 0.4578, train/hateful_memes/cross_entropy/avg: 0.4334, train/total_loss: 0.4978, train/total_loss/avg: 0.4337, experiment: run, epoch: 4, num_updates: 900, iterations: 900, max_updates: 1000, lr: 0.00002, ups: 0.13, time: 13m 02s 684ms, time_since_start: 02h 04m 36s 094ms, eta: 02h 20m 70s 557ms\u001b[0m\n",
            "\u001b[32m2021-04-27T14:47:13 | mmf.trainers.core.training_loop:\u001b[0m  Evaluation time. Running on full training set...\u001b[0m\n",
            "\u001b[32m2021-04-27T14:47:13 | mmf.common.test_reporter:\u001b[0m  Predicting for hateful_memes\u001b[0m\n",
            "\u001b[32m2021-04-27T14:47:56 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T14:47:12 | mmf.utils.checkpoint:\u001b[0m  Saving best checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T14:47:18 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T14:47:39 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T14:47:39 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 900/1000, test/hateful_memes/cross_entropy: 0.7647, test/total_loss: 0.8147, test/hateful_memes/accuracy: 0.6712, test/hateful_memes/binary_f1: 0.4371, test/hateful_memes/roc_auc: 0.7048, num_updates: 900, epoch: 4, iterations: 900, max_updates: 1000, val_time: 01m 26s 848ms, best_update: 900, best_iteration: 900, best_test/hateful_memes/roc_auc: 0.704289\u001b[0m\n",
            "\u001b[32m2021-04-27T15:05:08 | mmf.trainers.callbacks.checkpoint:\u001b[0m  Checkpoint time. Saving a checkpoint.\u001b[0m\n",
            "\u001b[32m2021-04-27T15:05:08 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T15:05:13 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T15:05:30 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T15:05:30 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 1000/1000, train/hateful_memes/cross_entropy: 0.3864, train/hateful_memes/cross_entropy/avg: 0.4229, train/total_loss: 0.3864, train/total_loss/avg: 0.4229, experiment: run, epoch: 4, num_updates: 1000, iterations: 1000, max_updates: 1000, lr: 0.00003, ups: 0.13, time: 12m 50s 999ms, time_since_start: 02h 18m 53s 945ms, eta: 02h 34s 290ms\u001b[0m\n",
            "\u001b[32m2021-04-27T15:05:32 | mmf.trainers.core.training_loop:\u001b[0m  Evaluation time. Running on full training set...\u001b[0m\n",
            "\u001b[32m2021-04-27T15:05:32 | mmf.common.test_reporter:\u001b[0m  Predicting for hateful_memes\u001b[0m\n",
            "\u001b[32m2021-04-27T15:12:09 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation started!\u001b[0m\n",
            "\u001b[32m2021-04-27T15:12:17 | mmf.utils.checkpoint:\u001b[0m  Saving best checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T15:12:37 | mmf.utils.checkpoint:\u001b[0m  Saving current checkpoint\u001b[0m\n",
            "\u001b[32m2021-04-27T15:12:57 | mmf.utils.checkpoint:\u001b[0m  Checkpoint save operation finished!\u001b[0m\n",
            "\u001b[32m2021-04-27T15:12:59 | mmf.trainers.callbacks.logistics:\u001b[0m  progress: 1000/1000, test/hateful_memes/cross_entropy: 0.6522, test/total_loss: 0.6522, test/hateful_memes/accuracy: 0.6737, test/hateful_memes/binary_f1: 0.5126, test/hateful_memes/roc_auc: 0.7331, num_updates: 1000, epoch: 4, iterations: 1000, max_updates: 1000, val_time: 01m 23s 321ms, best_update: 1000, best_iteration: 1000, best_test/hateful_memes/roc_auc: 0.733110\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q2jIOaqANR2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}