{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishek0697/Detection-of-Hate-Speech-in-Multimodal-Memes/blob/main/Code/Experiments/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtDzMe2sBnfl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swXvxbxMBoFm"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v_pFiBi21jQ",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcb5d21a-4ffd-44c4-e929-e4778c2e6bde"
      },
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Mar  4 09:34:43 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    28W /  70W |   4820MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DRqRtCRB9Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7f53ef7-63f6-4062-b372-f1f848542ab2"
      },
      "source": [
        "# !pip install transformers~=2.11.0\n",
        "!pip install transformers~=4.3.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers~=4.3.3 in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers~=4.3.3) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers~=4.3.3) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers~=4.3.3) (0.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers~=4.3.3) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers~=4.3.3) (0.0.43)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers~=4.3.3) (3.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers~=4.3.3) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers~=4.3.3) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers~=4.3.3) (20.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=4.3.3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=4.3.3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=4.3.3) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=4.3.3) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers~=4.3.3) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers~=4.3.3) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers~=4.3.3) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers~=4.3.3) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers~=4.3.3) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers~=4.3.3) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z4RwWDY21jm"
      },
      "source": [
        "'''Importing necessary modules\n",
        "'''\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "sys.path.append('./Trainers/')\n",
        "sys.path.append('./Dataloaders/')\n",
        "sys.path.append('./utils/')\n",
        "sys.path.append('/content/gdrive/MyDrive/Kaggle/Hateful meme detection local files')\n",
        "\n",
        "from dataloader import mydataset\n",
        "'''\n",
        "For BERT\n",
        "'''\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from trainer_BERT import train, test_classify\n",
        "from Load_model import load"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OojgTSi721jn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ff5a924-f88f-412b-af50-fc3ddd55bca0"
      },
      "source": [
        "# Select gpu\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRtr-zp21jp"
      },
      "source": [
        "**Dataloading Scheme**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO79cqYb21jq"
      },
      "source": [
        "trainlist = '/content/gdrive/MyDrive/Kaggle/facebook-hateful-meme-dataset/data/train.jsonl'\n",
        "validlist = '/content/gdrive/MyDrive/Kaggle/facebook-hateful-meme-dataset/data/dev.jsonl'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3bf6Dhu21jr"
      },
      "source": [
        "# prime_dict = create_prime_dict(trainlist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMgMqJky21js",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c04fe142-3aa4-48b6-ba91-45ad2c54e741"
      },
      "source": [
        "'''\n",
        "Train Dataloader\n",
        "''' \n",
        "train_dataset = mydataset(trainlist, name='train')          \n",
        "train_dataloader = data.DataLoader(train_dataset, shuffle= True, batch_size = 32, num_workers=16,pin_memory=True)\n",
        "\n",
        "\n",
        "'''\n",
        "Validation Dataloader\n",
        "''' \n",
        "validation_dataset = mydataset(validlist, name='valid')         \n",
        "validation_dataloader = data.DataLoader(validation_dataset, shuffle=False, batch_size = 32, num_workers=16,pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGDSAGoI21ju"
      },
      "source": [
        "**Model Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9QHdLg421jv",
        "outputId": "bf046d4e-5bc9-4d3c-cd3f-c3b8cd21e7ed"
      },
      "source": [
        "'''\n",
        "Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top.\n",
        "''' \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", #12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, #Binary classification\n",
        "    output_attentions = True, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "model = nn.DataParallel(model,device_ids=[0]).to(device)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iHM6hmt21jw"
      },
      "source": [
        "**Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aul3cO_321jx"
      },
      "source": [
        "'''\n",
        "Loss Function\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "'''\n",
        "Optimizer\n",
        "'''\n",
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
        "\n",
        "'''\n",
        "Number of training epochs. The BERT authors recommend between 2 and 4. We chose to run for 4, but we'll see later that this may be over-fitting the training data.\n",
        "'''\n",
        "num_Epochs = 10\n",
        "\n",
        "\n",
        "'''\n",
        "Create the learning rate scheduler.\n",
        "Total number of training steps is [number of batches] x [number of epochs].\n",
        "Note that this is not the same as the number of training samples.\n",
        "'''\n",
        "total_steps = len(train_dataloader) * num_Epochs\n",
        "lr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0,  num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMqg5R1R21jy"
      },
      "source": [
        "modelname = 'BERT_basic'\n",
        "modelpath = '/content/gdrive/MyDrive/Kaggle/saved_model_checkpoints/new/'+modelname"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsyuMX0n21jy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82843552-8b1d-4349-a8b8-9d498158db30"
      },
      "source": [
        "writer = SummaryWriter(modelname)\n",
        "\n",
        "train(model, train_dataloader, validation_dataloader, criterion, optimizer, lr_scheduler, modelpath, writer, device, epochs = num_Epochs)\n",
        "\n",
        "writer.flush()\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss 0.6178842473030091\n",
            "loss 1.1973635482788085\n",
            "Epoch:  1\n",
            "training loss =  0.5882176616810318\n",
            "Validation Loss: 0.7871\tTop 1 Validation Accuracy: 0.5660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss 0.5155595102906227\n",
            "loss 1.037861301600933\n",
            "Epoch:  2\n",
            "training loss =  0.5131523501604123\n",
            "Validation Loss: 0.8528\tTop 1 Validation Accuracy: 0.5580\n",
            "loss 0.4101566496491432\n",
            "loss 0.8612087018787861\n",
            "Epoch:  3\n",
            "training loss =  0.43874646135066686\n",
            "Validation Loss: 0.9157\tTop 1 Validation Accuracy: 0.5380\n",
            "loss 0.3697449783980846\n",
            "loss 0.7572229799628257\n",
            "Epoch:  4\n",
            "training loss =  0.3824126777008064\n",
            "Validation Loss: 1.0431\tTop 1 Validation Accuracy: 0.5340\n",
            "loss 0.3060436261445284\n",
            "loss 0.648694257363677\n",
            "Epoch:  5\n",
            "training loss =  0.33361895183535445\n",
            "Validation Loss: 1.2518\tTop 1 Validation Accuracy: 0.5300\n",
            "loss 0.27918849892914294\n",
            "loss 0.5871433471888303\n",
            "Epoch:  6\n",
            "training loss =  0.30002638728434877\n",
            "Validation Loss: 1.3783\tTop 1 Validation Accuracy: 0.5420\n",
            "loss 0.2599613666534424\n",
            "loss 0.5435575449466705\n",
            "Epoch:  7\n",
            "training loss =  0.2744963364605617\n",
            "Validation Loss: 1.5002\tTop 1 Validation Accuracy: 0.5300\n",
            "loss 0.2530093207210302\n",
            "loss 0.5136955760419368\n",
            "Epoch:  8\n",
            "training loss =  0.2593877233172718\n",
            "Validation Loss: 1.5771\tTop 1 Validation Accuracy: 0.5440\n",
            "loss 0.2512958320230246\n",
            "loss 0.4904311233758926\n",
            "Epoch:  9\n",
            "training loss =  0.2456190982987558\n",
            "Validation Loss: 1.7922\tTop 1 Validation Accuracy: 0.5260\n",
            "loss 0.2213268282637\n",
            "loss 0.46124199640005825\n",
            "Epoch:  10\n",
            "training loss =  0.23276740036680735\n",
            "Validation Loss: 1.8776\tTop 1 Validation Accuracy: 0.5280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgWcVF6v21jz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apkfNYt821j0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19351bcc-4cf7-4eee-c16d-70bec90d4436"
      },
      "source": [
        "'''\n",
        "Load saved model from checkpoint  #####\n",
        "'''\n",
        "model, optimizer, lr_scheduler, train_loss, v_loss, v_acc, epoch = load(modelpath, model, optimizer, lr_scheduler)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:234: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vku7PJt121j0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "952b4a21-7291-402c-cabb-1822af77096b"
      },
      "source": [
        "model.module.classifier"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=768, out_features=2, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr7RoAiESQFa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}